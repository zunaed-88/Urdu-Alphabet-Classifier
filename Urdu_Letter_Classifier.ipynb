{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zunaed-88/Urdu-Alphabet-Classifier/blob/main/Urdu_Letter_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "#  **Urdu Handwritten Alphabets Classifier**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 1** **INCEPTION VERSION 3**\n"
      ],
      "metadata": {
        "id": "YSNUx2dUkyXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Making a directory and fetching data form kaggle through API"
      ],
      "metadata": {
        "id": "6xLSDBM8tsXm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG"
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "_GOaAjILPJ5X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#URDU ALBHABETS DATASET BY HAZRAT ALI (https://www.kaggle.com/datasets/hazrat/uhat-urdu-handwritten-text-dataset)\n",
        "! kaggle datasets download -d hazrat/uhat-urdu-handwritten-text-dataset"
      ],
      "metadata": {
        "id": "fvlp5SBEPOW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/uhat-urdu-handwritten-text-dataset.zip' , 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "oy_MefkzrEe1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ke47hTyTQaKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r_iZ-4h3A4qP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import img_to_array, load_img, array_to_img\n",
        "from tensorflow.keras.layers import Dense,Flatten ,Dropout, BatchNormalization,Rescaling\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making data_paths\n",
        "data_path = '/content/data/data'\n",
        "train_path = '/content/data/data/characters_train_set'\n",
        "test_path = '/content/data/data/characters_test_set'"
      ],
      "metadata": {
        "id": "U9f2E7iZPbjy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_width =224\n",
        "img_height =224\n",
        "input_shape = (224,224,3)"
      ],
      "metadata": {
        "id": "yVQcFBuYPgSq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing the data in training and validation sets\n",
        "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "                  train_path,\n",
        "                  validation_split = 0.1,\n",
        "                  subset=\"both\",\n",
        "                  seed=42,\n",
        "                  image_size=(img_height, img_width),\n",
        "                  batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "TaAsN49lPiGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classes in the datasets, total 40 classes are in the dataset\n",
        "classes = train_ds.class_names\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "3jkLA1b2PmG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217209e9-20f7-464a-afff-9732b44e9f19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alif', 'alif mad aa', 'ayn', 'baa', 'bari yaa', 'cheey', 'choti yaa', 'daal', 'dhaal', 'faa', 'gaaf', 'ghain', 'haa1', 'haa2', 'haa3', 'hamza', 'jeem', 'kaaf', 'khaa', 'laam', 'meem', 'noon', 'noonghunna', 'paa', 'qaaf', 'raa', 'rhraa', 'seen', 'seey', 'sheen', 'swaad', 'taa', 'ttaa', 'twa', 'waw', 'zaaa', 'zaal', 'zhaa', 'zwaa', 'zwaad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning indices to classes\n",
        "idx_to_classes = {idx: classes for idx, classes in enumerate(classes)}\n",
        "print(idx_to_classes)"
      ],
      "metadata": {
        "id": "bM3wZ6UjPmvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc2a871-47d7-40d3-e9ee-2099749619b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'alif', 1: 'alif mad aa', 2: 'ayn', 3: 'baa', 4: 'bari yaa', 5: 'cheey', 6: 'choti yaa', 7: 'daal', 8: 'dhaal', 9: 'faa', 10: 'gaaf', 11: 'ghain', 12: 'haa1', 13: 'haa2', 14: 'haa3', 15: 'hamza', 16: 'jeem', 17: 'kaaf', 18: 'khaa', 19: 'laam', 20: 'meem', 21: 'noon', 22: 'noonghunna', 23: 'paa', 24: 'qaaf', 25: 'raa', 26: 'rhraa', 27: 'seen', 28: 'seey', 29: 'sheen', 30: 'swaad', 31: 'taa', 32: 'ttaa', 33: 'twa', 34: 'waw', 35: 'zaaa', 36: 'zaal', 37: 'zhaa', 38: 'zwaa', 39: 'zwaad'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let us show the different urdu alphabets\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(18):\n",
        "    ax = plt.subplot(3, 6, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(classes[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "idVCgOVzPomJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "FaQaC5zAPrAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples_per_batch = print('train_samples_per_batch =', len(train_ds))\n",
        "testing_samples_per_batch = print('testing_samples_per_batch =', len(val_ds))"
      ],
      "metadata": {
        "id": "GmkhqVAKPv5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2cdc01-b326-4215-fd49-61f068daffef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_samples_per_batch = 797\n",
            "testing_samples_per_batch = 89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class_indices have the numeric tag for each word\n",
        "import pickle\n",
        "TrainClasses=idx_to_classes\n",
        "\n",
        "# Storing the face and the numeric tag for future reference\n",
        "ResultMap={}\n",
        "for word, wordValue in zip(idx_to_classes.values(),idx_to_classes.keys()):\n",
        "    ResultMap[wordValue]=word\n",
        "\n",
        "# Saving the face map for future reference\n",
        "\n",
        "with open(R\"E:\\Data Sets\\Balls Classification\\ResultsMap.pkl\", 'wb') as f:\n",
        "    pickle.dump(ResultMap, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"Mapping of Face and its ID\",ResultMap)\n",
        "\n",
        "# The number of neurons for the output layer is equal to the number of faces\n",
        "OutputNeurons=len(ResultMap)\n",
        "print('\\n The Number of output neurons: ', OutputNeurons)"
      ],
      "metadata": {
        "id": "KId1PSD8o59F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_filepath = '/content/drive/MyDrive/Colab Notebooks/call_backs'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath = model_filepath,\n",
        "    monitor = 'val_accuracy',\n",
        "    mode = 'max',\n",
        "    save_best_only = True,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "NLiBvYz3PwdM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "eGZ1XJ7yP00M"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_inceptV3= InceptionV3(weights = \"imagenet\", include_top=False, input_shape = (224,224, 3))\n"
      ],
      "metadata": {
        "id": "PZeSOeBGP3R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b379b639-fd9c-4f9b-a1c6-853022fd3777"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "CPU times: user 5.15 s, sys: 456 ms, total: 5.61 s\n",
            "Wall time: 6.54 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_inceptV3.summary()"
      ],
      "metadata": {
        "id": "eZCKcbWrP5y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_inceptV3.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "Imb1xA04P79e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inceptV3.summary()"
      ],
      "metadata": {
        "id": "HsXmnSN6P9wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#freezing the extractor and saving last layer\n",
        "last_layer_inceptV3= model_inceptV3.get_layer('mixed10') #Saving the last layer of the network\n",
        "\n",
        "last_layer_output = last_layer_inceptV3.output #Saving the output of the last layer to be the input of the next layer\n",
        "\n",
        "x = Flatten()(last_layer_output) #Flattenning the classifier input, which is the output of the last layer of the inception model\n",
        "x = Rescaling(1./255)(x)\n",
        "x = Dense(50, activation='relu', name='FC_2')(x) #Adding 1 dense layer of 64 neurons\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(40, activation='softmax', name='classifer')(x) # our dataset is 40 class dataset, putting 40 softmax neuron to it\n",
        "\n",
        "\n",
        "model_inceptV3 = Model(inputs=model_inceptV3.input, outputs=x) #Instantiating a new_model\n"
      ],
      "metadata": {
        "id": "JO1ALhhGP_zB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inceptV3.summary()"
      ],
      "metadata": {
        "id": "U5fx2XriQB-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inceptV3.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "l3tALozVQFiK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Training the model\n",
        "history_inceptV3 = model_inceptV3.fit(train_ds, batch_size=batch_size, steps_per_epoch=len(train_ds), epochs=10,\n",
        "                    verbose=1, validation_data=val_ds , callbacks =[checkpoint])"
      ],
      "metadata": {
        "id": "3I2le3WOQI5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATING INCEPTION V3 PERFORMANCE**"
      ],
      "metadata": {
        "id": "mhinr9Sq1zp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the learning curves for train and test accuracy\n",
        "plt.plot(history_inceptV3.history['accuracy'], label='Train')\n",
        "plt.plot(history_inceptV3.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "stDihLmKQJsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the learning curves for train and test loss\n",
        "plt.plot(history_inceptV3.history['loss'], label='Train')\n",
        "plt.plot(history_inceptV3.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3WCkdnQEQLuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inceptV3.metrics_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w90bqnhxQN-f",
        "outputId": "283108bd-ac84-4540-f90f-9a54265108ec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'accuracy']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us print the loss function value and overall accuracy of our model on train as well as test data.\n",
        "train_loss, train_accuracy = model_inceptV3.evaluate(train_ds)\n",
        "val_loss, val_accuracy = model_inceptV3.evaluate(val_ds)\n",
        "print(f'Train loss is {train_loss:0.3} and train accuracy is {train_accuracy:0.1%}')\n",
        "print(f'validation loss is {val_loss:0.3} and validation accuracy is {val_accuracy:0.1%}')"
      ],
      "metadata": {
        "id": "WC0ex_ZpQRsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba901c05-1d88-4c3d-db7b-be80544a70a0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "797/797 [==============================] - 2911s 4s/step - loss: 0.5370 - accuracy: 0.8595\n",
            "89/89 [==============================] - 324s 4s/step - loss: 0.6257 - accuracy: 0.8358\n",
            "Train loss is 0.537 and train accuracy is 86.0%\n",
            "validation loss is 0.626 and validation accuracy is 83.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAKING INDIVIDUAL PREDICTIONS ON INCEPTIONV3**"
      ],
      "metadata": {
        "id": "QKYEywoB6C2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZABJp7T3VLCU"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size=(224, 224))\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model_inceptV3.predict(images, batch_size=10)\n",
        "  print(fn)\n",
        "  print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 2 DenseNet121**"
      ],
      "metadata": {
        "id": "_Jt-mZD8JnIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import DenseNet121"
      ],
      "metadata": {
        "id": "V35suFcRIxSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        " model_Dens= DenseNet121(weights = \"imagenet\", include_top=False, input_shape = (224,224, 3))"
      ],
      "metadata": {
        "id": "KM4MaG3LI3xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_Dens.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "UwCL3BsII4dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Dens.summary()"
      ],
      "metadata": {
        "id": "Q07fCV7mI7aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#freezing the extractor and saving last layer\n",
        "last_layer_Dens = model_Dens.get_layer('relu') #Saving the last layer of the network\n",
        "\n",
        "last_layer_output = last_layer_Dens.output #Saving the output of the last layer to be the input of the next layer\n",
        "\n",
        "x = Flatten()(last_layer_output) #Flattenning the classifier input, which is the output of the last layer of the DensNet121\n",
        "x = Rescaling(1./255)(x) #adding rescaling layer\n",
        "x = Dense(50, activation='relu', name='FC_2')(x) #Adding 1 dense layer of 64 neurons\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(40, activation='softmax', name='classifer')(x) #Adding our new softmax layer with two hidden units\n",
        "\n",
        "model_Dens = Model(inputs=model_Dens.input, outputs=x) #Instantiating a new_model\n"
      ],
      "metadata": {
        "id": "uRXvmj2YI9nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Dens.summary()"
      ],
      "metadata": {
        "id": "ON_VinGuJDdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Dens.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0CB-5mZbJEPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history_Dens = model_Dens.fit(train_ds, epochs= 3, verbose = 0, validation_data=val_ds,steps_per_epoch=len(train_ds), callbacks =[checkpoint])"
      ],
      "metadata": {
        "id": "7yLdpl4PJJWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATING DENSNET121 PERFORMANCE**\n"
      ],
      "metadata": {
        "id": "wlN0_OrzbPUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the learning curves for train and test accuracy\n",
        "plt.plot(history_Dens.history['accuracy'], label='Train')\n",
        "plt.plot(history_Dens.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Sg90heUJNKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the learning curves for train and test loss\n",
        "plt.plot(history_Dens.history['loss'], label='Train')\n",
        "plt.plot(history_Dens.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F2K9G_qOJQUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Dens.metrics_names"
      ],
      "metadata": {
        "id": "C37_Iiu3JUpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us print the loss function value and overall accuracy of our model on train as well as test data.\n",
        "train_loss, train_accuracy = model_Dens.evaluate(train_ds)\n",
        "val_loss, val_accuracy = model_Dens.evaluate(val_ds)\n",
        "print(f'Train loss is {train_loss:0.3} and train accuracy is {train_accuracy:0.1%}')\n",
        "print(f'validation loss is {val_loss:0.3} and validaiton accuracy is {val_accuracy:0.1%}')"
      ],
      "metadata": {
        "id": "I5Nfm1fKJVZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAKING INDIVIDUAL PREDICTIONS ON DENSNET121**"
      ],
      "metadata": {
        "id": "fkHZNm0o2mlv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o_3HM0IQFiQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size=(224, 224))\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model_inceptV3.predict(images, batch_size=10)\n",
        "  print(fn)\n",
        "  print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**END**"
      ],
      "metadata": {
        "id": "J5KXxus67YKo"
      }
    }
  ]
}